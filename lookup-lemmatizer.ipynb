{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-4-5e736c0be48d>, line 80)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-5e736c0be48d>\"\u001b[1;36m, line \u001b[1;32m80\u001b[0m\n\u001b[1;33m    accuracies['Expected lookup'] = ### Calculate expected accuracy if we used lookup on all items ###\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "### This program is a very simple lemmatizer, which learns a\n",
    "### lemmatization function from an annotated corpus. The function is\n",
    "### so basic I wouldn't even consider it machine learning: it's\n",
    "### basically just a big lookup table, which maps every word form\n",
    "### attested in the training data to the most common lemma associated\n",
    "### with that form. At test time, the program checks if a form is in\n",
    "### the lookup table, and if so, it gives the associated lemma; if the\n",
    "### form is not in the lookup table, it gives the form itself as the\n",
    "### lemma (identity mapping).\n",
    "\n",
    "### The program performs training and testing in one run: it reads the\n",
    "### training data, learns the lookup table and keeps it in memory,\n",
    "### then reads the test data, runs the testing, and reports the\n",
    "### results.\n",
    "\n",
    "### The program takes two command line arguments, which are the paths\n",
    "### to the training and test files. Both files are assumed to be\n",
    "### already tokenized, in Universal Dependencies format, that is: each\n",
    "### token on a separate line, each line consisting of fields separated\n",
    "### by tab characters, with word form in the second field, and lemma\n",
    "### in the third field. Tab characters are assumed to occur only in\n",
    "### lines corresponding to tokens; other lines are ignored.\n",
    "\n",
    "import sys\n",
    "import re\n",
    "\n",
    "### Global variables\n",
    "\n",
    "# Paths for data are read from command line\n",
    "train_file = sys.argv[1]\n",
    "test_file = sys.argv[2]\n",
    "\n",
    "# Counters for lemmas in the training data: word form -> lemma -> count\n",
    "lemma_count = {}\n",
    "\n",
    "# Lookup table learned from the training data: word form -> lemma\n",
    "lemma_max = {}\n",
    "\n",
    "# Variables for reporting results\n",
    "training_stats = ['Wordform types' , 'Wordform tokens' , 'Unambiguous types' , 'Unambiguous tokens' , 'Ambiguous types' , 'Ambiguous tokens' , 'Ambiguous most common tokens' , 'Identity tokens']\n",
    "training_counts = dict.fromkeys(training_stats , 0)\n",
    "\n",
    "test_outcomes = ['Total test items' , 'Found in lookup table' , 'Lookup match' , 'Lookup mismatch' , 'Not found in lookup table' , 'Identity match' , 'Identity mismatch']\n",
    "test_counts = dict.fromkeys(test_outcomes , 0)\n",
    "\n",
    "accuracies = {}\n",
    "\n",
    "### Training: read training data and populate lemma counters\n",
    "\n",
    "train_data = open (train_file , 'r')\n",
    "\n",
    "for line in train_data:\n",
    "    \n",
    "    # Tab character identifies lines containing tokens\n",
    "    if re.search ('\\t' , line):\n",
    "\n",
    "        # Tokens represented as tab-separated fields\n",
    "        field = line.strip().split('\\t')\n",
    "\n",
    "        # Word form in second field, lemma in third field\n",
    "        form = field[1]\n",
    "        lemma = field[2]\n",
    "\n",
    "        ######################################################\n",
    "        ### Insert code for populating the lemma counts  e.g. {A : {B:30, C:39}}  ###\n",
    "        ######################################################\n",
    "\n",
    "### Model building and training statistics\n",
    "        \n",
    "for form in lemma_count.keys():\n",
    "\n",
    "        ######################################################\n",
    "        ### Insert code for building the lookup table   From lemma count get most max lemma per wrod form  ###\n",
    "        ######################################################\n",
    "\n",
    "        ######################################################\n",
    "        ### Insert code for populating the training counts Get the datas out of it ###\n",
    "        ######################################################\n",
    "\n",
    "accuracies['Expected lookup'] = ### Calculate expected accuracy if we used lookup on all items ###\n",
    "\n",
    "accuracies['Expected identity'] = ### Calculate expected accuracy if we used identity mapping on all items ###\n",
    "\n",
    "### Testing: read test data, and compare lemmatizer output to actual lemma\n",
    "    \n",
    "test_data = open (test_file , 'r')\n",
    "\n",
    "for line in test_data:\n",
    "\n",
    "    # Tab character identifies lines containing tokens\n",
    "    if re.search ('\\t' , line):\n",
    "\n",
    "        # Tokens represented as tab-separated fields\n",
    "        field = line.strip().split('\\t')\n",
    "\n",
    "        # Word form in second field, lemma in third field\n",
    "        form = field[1]\n",
    "        lemma = field[2]\n",
    "\n",
    "        ######################################################\n",
    "        ### Insert code for populating the test counts   If form -> lemma matches with lookup table that will increase Acc. If no match Try Identity.  ###\n",
    "        ######################################################\n",
    "\n",
    "accuracies['Lookup'] = ### Calculate accuracy on the items that used the lookup table ###\n",
    "\n",
    "accuracies['Identity'] = ### Calculate accuracy on the items that used identity mapping ###\n",
    "\n",
    "accuracies['Overall'] = ### Calculate overall accuracy ###\n",
    "\n",
    "### Report training statistics and test results\n",
    "                \n",
    "output = open ('lookup-output.txt' , 'w')\n",
    "\n",
    "output.write ('Training statistics\\n')\n",
    "\n",
    "for stat in training_stats:\n",
    "    output.write (stat + ': ' + str(training_counts[stat]) + '\\n')\n",
    "\n",
    "for model in ['Expected lookup' , 'Expected identity']:\n",
    "    output.write (model + ' accuracy: ' + str(accuracies[model]) + '\\n')\n",
    "\n",
    "output.write ('Test results\\n')\n",
    "\n",
    "for outcome in test_outcomes:\n",
    "    output.write (outcome + ': ' + str(test_counts[outcome]) + '\\n')\n",
    "\n",
    "for model in ['Lookup' , 'Identity' , 'Overall']:\n",
    "    output.write (model + ' accuracy: ' + str(accuracies[model]) + '\\n')\n",
    "\n",
    "output.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='./data/hi_hdtb-ud-train.conllu' mode='r' encoding='cp949'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not _io.TextIOWrapper",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-bb35cdd558ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'lookup-output.txt'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: write() argument must be str, not _io.TextIOWrapper"
     ]
    }
   ],
   "source": [
    "train_data = open('./data/hi_hdtb-ud-train.conllu' , 'r')\n",
    "print(train_data)\n",
    "\n",
    "output = open ('lookup-output.txt' , 'w')\n",
    "output.write(train_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
